{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e284f92a-1b8e-467b-b425-f2d9533b7a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/02/02 03:15:14 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "26/02/02 03:15:27 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Departamentos por contratación:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   departamento  total_contratado\n",
      "0         VALLE      394161052301\n",
      "1       BOLIVAR      386120570040\n",
      "2     ATLANTICO      384507061234\n",
      "3  CUNDINAMARCA      378536228613\n",
      "4     ANTIOQUIA      351958791420\n",
      "5     SANTANDER      343270735552\n",
      "6        BOGOTA      326788630428\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # 3. Analítica (Capa Oro)\n",
    "# Agregaciones de negocio.\n",
    "\n",
    "# %%\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum, desc, col\n",
    "from delta import *\n",
    "\n",
    "builder = SparkSession.builder \\\n",
    "    .appName(\"Lab_SECOP_Gold\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-spark_2.12:3.0.0\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "# %%\n",
    "# Leer Plata\n",
    "df_silver = spark.read.format(\"delta\").load(\"/app/data/lakehouse/silver/secop\")\n",
    "\n",
    "# %%\n",
    "# Agregación (Shuffle)\n",
    "df_gold = df_silver \\\n",
    "    .groupBy(\"departamento\") \\\n",
    "    .agg(sum(\"precio_base\").alias(\"total_contratado\")) \\\n",
    "    .orderBy(desc(\"total_contratado\")) \\\n",
    "    .limit(10)\n",
    "\n",
    "# %%\n",
    "# Persistir Oro\n",
    "df_gold.write.format(\"delta\").mode(\"overwrite\").save(\"/app/data/lakehouse/gold/top_deptos\")\n",
    "\n",
    "# %%\n",
    "# Visualizar\n",
    "print(\"Top 10 Departamentos por contratación:\")\n",
    "df_pandas = df_gold.toPandas()\n",
    "print(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f0afd-d572-4d71-b6d8-d1ed29da436e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
